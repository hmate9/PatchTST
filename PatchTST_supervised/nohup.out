Traceback (most recent call last):
  File "/home/ubuntu/PatchTST/PatchTST_supervised/run_longExp.py", line 3, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
Traceback (most recent call last):
  File "/home/ubuntu/PatchTST/PatchTST_supervised/run_longExp.py", line 3, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
Traceback (most recent call last):
  File "/home/ubuntu/PatchTST/PatchTST_supervised/run_longExp.py", line 3, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
Traceback (most recent call last):
  File "/home/ubuntu/PatchTST/PatchTST_supervised/run_longExp.py", line 3, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='240_1', model='PatchTST', data='custom', root_path='../', data_path='BTCUSDT_1h_features.csv', features='M', target='ibs', freq='h', checkpoints='./checkpoints/', seq_len=240, label_len=48, pred_len=1, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=300, batch_size=1024, patience=15, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.2, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : 240_1_PatchTST_custom_ftM_sl240_ll48_pl1_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 20745
val 2999
test 5995
Epoch: 1 cost time: 12.18378472328186
Epoch: 1, Steps: 20 | Train Loss: 1.3088907 Vali Loss: 0.8555783 Test Loss: 0.7450758
Validation loss decreased (inf --> 0.855578).  Saving model ...
Updating learning rate to 4.065892081076648e-06
Epoch: 2 cost time: 12.159696102142334
Epoch: 2, Steps: 20 | Train Loss: 1.2602227 Vali Loss: 0.8333300 Test Loss: 0.7244316
Validation loss decreased (0.855578 --> 0.833330).  Saving model ...
Updating learning rate to 4.263387417375412e-06
Epoch: 3 cost time: 12.231781005859375
Epoch: 3, Steps: 20 | Train Loss: 1.2002291 Vali Loss: 0.7895349 Test Loss: 0.6907288
Validation loss decreased (0.833330 --> 0.789535).  Saving model ...
Updating learning rate to 4.5919437847832866e-06
Epoch: 4 cost time: 12.308899164199829
Epoch: 4, Steps: 20 | Train Loss: 1.1545789 Vali Loss: 0.7546504 Test Loss: 0.6555434
Validation loss decreased (0.789535 --> 0.754650).  Saving model ...
Updating learning rate to 5.050659130683655e-06
Epoch: 5 cost time: 12.352943897247314
Epoch: 5, Steps: 20 | Train Loss: 1.0950866 Vali Loss: 0.7230574 Test Loss: 0.6203346
Validation loss decreased (0.754650 --> 0.723057).  Saving model ...
Updating learning rate to 5.638274050544684e-06
Epoch: 6 cost time: 12.366722345352173
Epoch: 6, Steps: 20 | Train Loss: 1.0449468 Vali Loss: 0.6704808 Test Loss: 0.5855277
Validation loss decreased (0.723057 --> 0.670481).  Saving model ...
Updating learning rate to 6.353175245618837e-06
Epoch: 7 cost time: 12.485228776931763
Epoch: 7, Steps: 20 | Train Loss: 0.9883117 Vali Loss: 0.6477900 Test Loss: 0.5510393
Validation loss decreased (0.670481 --> 0.647790).  Saving model ...
Updating learning rate to 7.193399952259961e-06
Epoch: 8 cost time: 12.610529899597168
Epoch: 8, Steps: 20 | Train Loss: 0.9374291 Vali Loss: 0.5932370 Test Loss: 0.5173554
Validation loss decreased (0.647790 --> 0.593237).  Saving model ...
Updating learning rate to 8.156641330697527e-06
Epoch: 9 cost time: 12.667353391647339
Epoch: 9, Steps: 20 | Train Loss: 0.8851940 Vali Loss: 0.5597624 Test Loss: 0.4852313
Validation loss decreased (0.593237 --> 0.559762).  Saving model ...
Updating learning rate to 9.240254798473037e-06
Epoch: 10 cost time: 12.657424926757812
Epoch: 10, Steps: 20 | Train Loss: 0.8397794 Vali Loss: 0.5284957 Test Loss: 0.4555025
Validation loss decreased (0.559762 --> 0.528496).  Saving model ...
Updating learning rate to 1.0441265291150027e-05
Epoch: 11 cost time: 12.75452446937561
Epoch: 11, Steps: 20 | Train Loss: 0.7931251 Vali Loss: 0.4892652 Test Loss: 0.4289823
Validation loss decreased (0.528496 --> 0.489265).  Saving model ...
Updating learning rate to 1.1756375430363637e-05
Epoch: 12 cost time: 12.808420419692993
Epoch: 12, Steps: 20 | Train Loss: 0.7537454 Vali Loss: 0.4792836 Test Loss: 0.4064604
Validation loss decreased (0.489265 --> 0.479284).  Saving model ...
Updating learning rate to 1.3181974576783947e-05
Epoch: 13 cost time: 12.772569179534912
Epoch: 13, Steps: 20 | Train Loss: 0.7205822 Vali Loss: 0.4408812 Test Loss: 0.3882998
Validation loss decreased (0.479284 --> 0.440881).  Saving model ...
Updating learning rate to 1.4714148743138502e-05
Epoch: 14 cost time: 12.84816312789917
Epoch: 14, Steps: 20 | Train Loss: 0.6906696 Vali Loss: 0.4168505 Test Loss: 0.3743235
Validation loss decreased (0.440881 --> 0.416850).  Saving model ...
Updating learning rate to 1.634869134007758e-05
Epoch: 15 cost time: 12.59047245979309
Epoch: 15, Steps: 20 | Train Loss: 0.6665372 Vali Loss: 0.4182075 Test Loss: 0.3636558
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.8081114725379524e-05
Epoch: 16 cost time: 12.311275720596313
Epoch: 16, Steps: 20 | Train Loss: 0.6535167 Vali Loss: 0.3989075 Test Loss: 0.3558718
Validation loss decreased (0.416850 --> 0.398907).  Saving model ...
Updating learning rate to 1.990666252478751e-05
Epoch: 17 cost time: 12.182673931121826
Epoch: 17, Steps: 20 | Train Loss: 0.6361681 Vali Loss: 0.3976988 Test Loss: 0.3498690
Validation loss decreased (0.398907 --> 0.397699).  Saving model ...
Updating learning rate to 2.1820322690651182e-05
Epoch: 18 cost time: 12.25246262550354
Epoch: 18, Steps: 20 | Train Loss: 0.6296436 Vali Loss: 0.3882435 Test Loss: 0.3449215
Validation loss decreased (0.397699 --> 0.388243).  Saving model ...
Updating learning rate to 2.381684126252048e-05
Epoch: 19 cost time: 12.246911764144897
Epoch: 19, Steps: 20 | Train Loss: 0.6160915 Vali Loss: 0.3865927 Test Loss: 0.3403125
Validation loss decreased (0.388243 --> 0.386593).  Saving model ...
Updating learning rate to 2.5890736791911714e-05
Epoch: 20 cost time: 12.226217985153198
Epoch: 20, Steps: 20 | Train Loss: 0.6081180 Vali Loss: 0.3736582 Test Loss: 0.3361774
Validation loss decreased (0.386593 --> 0.373658).  Saving model ...
Updating learning rate to 2.803631539164287e-05
Epoch: 21 cost time: 12.199304342269897
Epoch: 21, Steps: 20 | Train Loss: 0.6014344 Vali Loss: 0.3681966 Test Loss: 0.3323562
Validation loss decreased (0.373658 --> 0.368197).  Saving model ...
Updating learning rate to 3.024768636842028e-05
Epoch: 22 cost time: 12.21655797958374
Epoch: 22, Steps: 20 | Train Loss: 0.5905038 Vali Loss: 0.3731350 Test Loss: 0.3285226
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.2518778395756694e-05
Epoch: 23 cost time: 12.29166293144226
Epoch: 23, Steps: 20 | Train Loss: 0.5820386 Vali Loss: 0.3793818 Test Loss: 0.3249795
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.484335618281891e-05
Epoch: 24 cost time: 12.214315176010132
Epoch: 24, Steps: 20 | Train Loss: 0.5730470 Vali Loss: 0.3748596 Test Loss: 0.3212374
EarlyStopping counter: 3 out of 15
Updating learning rate to 3.721503759343966e-05
Epoch: 25 cost time: 12.234743595123291
Epoch: 25, Steps: 20 | Train Loss: 0.5654975 Vali Loss: 0.3530505 Test Loss: 0.3179554
Validation loss decreased (0.368197 --> 0.353050).  Saving model ...
Updating learning rate to 3.962731116829408e-05
Epoch: 26 cost time: 12.271178722381592
Epoch: 26, Steps: 20 | Train Loss: 0.5604289 Vali Loss: 0.3428058 Test Loss: 0.3147606
Validation loss decreased (0.353050 --> 0.342806).  Saving model ...
Updating learning rate to 4.207355400213329e-05
Epoch: 27 cost time: 12.28065037727356
Epoch: 27, Steps: 20 | Train Loss: 0.5526702 Vali Loss: 0.3563077 Test Loss: 0.3117316
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.454704992699311e-05
Epoch: 28 cost time: 12.30937671661377
Epoch: 28, Steps: 20 | Train Loss: 0.5467560 Vali Loss: 0.3575659 Test Loss: 0.3090194
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.7041007951455885e-05
Epoch: 29 cost time: 12.348791360855103
Epoch: 29, Steps: 20 | Train Loss: 0.5394711 Vali Loss: 0.3449394 Test Loss: 0.3064901
EarlyStopping counter: 3 out of 15
Updating learning rate to 4.9548580905340365e-05
Epoch: 30 cost time: 12.28207278251648
Epoch: 30, Steps: 20 | Train Loss: 0.5346728 Vali Loss: 0.3468576 Test Loss: 0.3038040
EarlyStopping counter: 4 out of 15
Updating learning rate to 5.2062884238630596e-05
Epoch: 31 cost time: 12.356368064880371
Epoch: 31, Steps: 20 | Train Loss: 0.5330126 Vali Loss: 0.3472573 Test Loss: 0.3016221
EarlyStopping counter: 5 out of 15
Updating learning rate to 5.4577014923031245e-05
Epoch: 32 cost time: 12.483439207077026
Epoch: 32, Steps: 20 | Train Loss: 0.5240112 Vali Loss: 0.3432694 Test Loss: 0.2998353
EarlyStopping counter: 6 out of 15
Updating learning rate to 5.708407040425505e-05
Epoch: 33 cost time: 12.496385097503662
Epoch: 33, Steps: 20 | Train Loss: 0.5166945 Vali Loss: 0.3419796 Test Loss: 0.2974339
Validation loss decreased (0.342806 --> 0.341980).  Saving model ...
Updating learning rate to 5.957716755300899e-05
Epoch: 34 cost time: 12.541420459747314
Epoch: 34, Steps: 20 | Train Loss: 0.5182994 Vali Loss: 0.3281370 Test Loss: 0.2956466
Validation loss decreased (0.341980 --> 0.328137).  Saving model ...
Updating learning rate to 6.204946156264901e-05
Epoch: 35 cost time: 12.68070650100708
Epoch: 35, Steps: 20 | Train Loss: 0.5093640 Vali Loss: 0.3437968 Test Loss: 0.2939580
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.449416474161976e-05
Epoch: 36 cost time: 12.652459859848022
Epoch: 36, Steps: 20 | Train Loss: 0.5070428 Vali Loss: 0.3239658 Test Loss: 0.2918038
Validation loss decreased (0.328137 --> 0.323966).  Saving model ...
Updating learning rate to 6.690456514908466e-05
Epoch: 37 cost time: 12.717838048934937
Epoch: 37, Steps: 20 | Train Loss: 0.4975745 Vali Loss: 0.3340741 Test Loss: 0.2905901
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.927404502258226e-05
Epoch: 38 cost time: 12.750542879104614
Epoch: 38, Steps: 20 | Train Loss: 0.4986985 Vali Loss: 0.3307293 Test Loss: 0.2891284
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.159609894711528e-05
Epoch: 39 cost time: 12.83256196975708
Epoch: 39, Steps: 20 | Train Loss: 0.4979053 Vali Loss: 0.3332689 Test Loss: 0.2877441
EarlyStopping counter: 3 out of 15
Updating learning rate to 7.386435171578959e-05
Epoch: 40 cost time: 12.76772427558899
Epoch: 40, Steps: 20 | Train Loss: 0.4813875 Vali Loss: 0.3223807 Test Loss: 0.2867252
Validation loss decreased (0.323966 --> 0.322381).  Saving model ...
Updating learning rate to 7.607257583296616e-05
Epoch: 41 cost time: 12.795416355133057
Epoch: 41, Steps: 20 | Train Loss: 0.4898160 Vali Loss: 0.3270351 Test Loss: 0.2852658
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.821470861187153e-05
Epoch: 42 cost time: 12.836265087127686
Epoch: 42, Steps: 20 | Train Loss: 0.4853263 Vali Loss: 0.3293338 Test Loss: 0.2845029
EarlyStopping counter: 2 out of 15
Updating learning rate to 8.028486881972461e-05
Epoch: 43 cost time: 12.833951473236084
Epoch: 43, Steps: 20 | Train Loss: 0.4823646 Vali Loss: 0.3212222 Test Loss: 0.2833821
Validation loss decreased (0.322381 --> 0.321222).  Saving model ...
Updating learning rate to 8.227737282468138e-05
Epoch: 44 cost time: 12.795423746109009
Epoch: 44, Steps: 20 | Train Loss: 0.4821045 Vali Loss: 0.3169332 Test Loss: 0.2826951
Validation loss decreased (0.321222 --> 0.316933).  Saving model ...
Updating learning rate to 8.418675020026516e-05
Epoch: 45 cost time: 12.831915378570557
Epoch: 45, Steps: 20 | Train Loss: 0.4785520 Vali Loss: 0.3026739 Test Loss: 0.2821765
Validation loss decreased (0.316933 --> 0.302674).  Saving model ...
Updating learning rate to 8.6007758744441e-05
Epoch: 46 cost time: 12.806113481521606
Epoch: 46, Steps: 20 | Train Loss: 0.4783694 Vali Loss: 0.3205068 Test Loss: 0.2819417
EarlyStopping counter: 1 out of 15
Updating learning rate to 8.773539887209924e-05
Epoch: 47 cost time: 12.810405015945435
Epoch: 47, Steps: 20 | Train Loss: 0.4752350 Vali Loss: 0.3313465 Test Loss: 0.2820637
EarlyStopping counter: 2 out of 15
Updating learning rate to 8.936492734143298e-05
Epoch: 48 cost time: 12.787900686264038
Epoch: 48, Steps: 20 | Train Loss: 0.4736533 Vali Loss: 0.3079813 Test Loss: 0.2812509
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.08918702765249e-05
Epoch: 49 cost time: 12.866777658462524
Epoch: 49, Steps: 20 | Train Loss: 0.4732860 Vali Loss: 0.3128684 Test Loss: 0.2808887
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.23120354503883e-05
Epoch: 50 cost time: 12.781012058258057
Epoch: 50, Steps: 20 | Train Loss: 0.4693498 Vali Loss: 0.3208297 Test Loss: 0.2806582
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.362152379474081e-05
Epoch: 51 cost time: 12.818070411682129
Epoch: 51, Steps: 20 | Train Loss: 0.4670991 Vali Loss: 0.3214758 Test Loss: 0.2805854
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.481674010490929e-05
Epoch: 52 cost time: 12.829559803009033
Epoch: 52, Steps: 20 | Train Loss: 0.4672555 Vali Loss: 0.3156418 Test Loss: 0.2800189
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.589440291047651e-05
Epoch: 53 cost time: 12.850167751312256
Epoch: 53, Steps: 20 | Train Loss: 0.4647415 Vali Loss: 0.3118991 Test Loss: 0.2800470
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.685155348456921e-05
Epoch: 54 cost time: 12.824143409729004
Epoch: 54, Steps: 20 | Train Loss: 0.4649265 Vali Loss: 0.3028979 Test Loss: 0.2799407
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.768556396705278e-05
Epoch: 55 cost time: 12.933818578720093
Epoch: 55, Steps: 20 | Train Loss: 0.4646509 Vali Loss: 0.3182186 Test Loss: 0.2799359
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.839414457933012e-05
Epoch: 56 cost time: 12.941343307495117
Epoch: 56, Steps: 20 | Train Loss: 0.4609211 Vali Loss: 0.3157140 Test Loss: 0.2796618
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.897534991093651e-05
Epoch: 57 cost time: 12.944838047027588
Epoch: 57, Steps: 20 | Train Loss: 0.4589677 Vali Loss: 0.3187815 Test Loss: 0.2790889
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.942758426067059e-05
Epoch: 58 cost time: 12.888321161270142
Epoch: 58, Steps: 20 | Train Loss: 0.4560390 Vali Loss: 0.3178575 Test Loss: 0.2790434
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.974960601759743e-05
Epoch: 59 cost time: 12.95597767829895
Epoch: 59, Steps: 20 | Train Loss: 0.4592060 Vali Loss: 0.3238541 Test Loss: 0.2788390
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.994053106989553e-05
Epoch: 60 cost time: 12.950543880462646
Epoch: 60, Steps: 20 | Train Loss: 0.4572294 Vali Loss: 0.3236921 Test Loss: 0.2790318
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : 240_1_PatchTST_custom_ftM_sl240_ll48_pl1_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5995
mse:0.2821764647960663, mae:0.31684228777885437, rse:0.6548543572425842
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='240_3', model='PatchTST', data='custom', root_path='../', data_path='BTCUSDT_1h_features.csv', features='M', target='ibs', freq='h', checkpoints='./checkpoints/', seq_len=240, label_len=48, pred_len=3, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=300, batch_size=1024, patience=15, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.2, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : 240_3_PatchTST_custom_ftM_sl240_ll48_pl3_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 20743
val 2997
test 5993
Epoch: 1 cost time: 12.92044448852539
Epoch: 1, Steps: 20 | Train Loss: 1.3319963 Vali Loss: 0.8331281 Test Loss: 0.7536680
Validation loss decreased (inf --> 0.833128).  Saving model ...
Updating learning rate to 4.065892081076648e-06
Epoch: 2 cost time: 12.838419914245605
Epoch: 2, Steps: 20 | Train Loss: 1.2846374 Vali Loss: 0.8268601 Test Loss: 0.7463825
Validation loss decreased (0.833128 --> 0.826860).  Saving model ...
Updating learning rate to 4.263387417375412e-06
Epoch: 3 cost time: 12.958163022994995
Epoch: 3, Steps: 20 | Train Loss: 1.2449929 Vali Loss: 0.8009648 Test Loss: 0.7208278
Validation loss decreased (0.826860 --> 0.800965).  Saving model ...
Updating learning rate to 4.5919437847832866e-06
Epoch: 4 cost time: 12.901689052581787
Epoch: 4, Steps: 20 | Train Loss: 1.1992747 Vali Loss: 0.7716374 Test Loss: 0.6926137
Validation loss decreased (0.800965 --> 0.771637).  Saving model ...
Updating learning rate to 5.050659130683655e-06
Epoch: 5 cost time: 12.886736869812012
Epoch: 5, Steps: 20 | Train Loss: 1.1550048 Vali Loss: 0.7502207 Test Loss: 0.6638569
Validation loss decreased (0.771637 --> 0.750221).  Saving model ...
Updating learning rate to 5.638274050544684e-06
Epoch: 6 cost time: 12.945621013641357
Epoch: 6, Steps: 20 | Train Loss: 1.1141128 Vali Loss: 0.7148622 Test Loss: 0.6346673
Validation loss decreased (0.750221 --> 0.714862).  Saving model ...
Updating learning rate to 6.353175245618837e-06
Epoch: 7 cost time: 12.964044570922852
Epoch: 7, Steps: 20 | Train Loss: 1.0715359 Vali Loss: 0.6955274 Test Loss: 0.6053008
Validation loss decreased (0.714862 --> 0.695527).  Saving model ...
Updating learning rate to 7.193399952259961e-06
Epoch: 8 cost time: 12.869112014770508
Epoch: 8, Steps: 20 | Train Loss: 1.0326460 Vali Loss: 0.6586723 Test Loss: 0.5760063
Validation loss decreased (0.695527 --> 0.658672).  Saving model ...
Updating learning rate to 8.156641330697527e-06
Epoch: 9 cost time: 12.957515239715576
Epoch: 9, Steps: 20 | Train Loss: 0.9852887 Vali Loss: 0.6307440 Test Loss: 0.5471108
Validation loss decreased (0.658672 --> 0.630744).  Saving model ...
Updating learning rate to 9.240254798473037e-06
Epoch: 10 cost time: 12.98062539100647
Epoch: 10, Steps: 20 | Train Loss: 0.9377000 Vali Loss: 0.5995940 Test Loss: 0.5193545
Validation loss decreased (0.630744 --> 0.599594).  Saving model ...
Updating learning rate to 1.0441265291150027e-05
Epoch: 11 cost time: 12.996145963668823
Epoch: 11, Steps: 20 | Train Loss: 0.9003853 Vali Loss: 0.5598215 Test Loss: 0.4930119
Validation loss decreased (0.599594 --> 0.559821).  Saving model ...
Updating learning rate to 1.1756375430363637e-05
Epoch: 12 cost time: 12.963330030441284
Epoch: 12, Steps: 20 | Train Loss: 0.8601316 Vali Loss: 0.5375239 Test Loss: 0.4691947
Validation loss decreased (0.559821 --> 0.537524).  Saving model ...
Updating learning rate to 1.3181974576783947e-05
Epoch: 13 cost time: 12.979362964630127
Epoch: 13, Steps: 20 | Train Loss: 0.8209697 Vali Loss: 0.5188352 Test Loss: 0.4484808
Validation loss decreased (0.537524 --> 0.518835).  Saving model ...
Updating learning rate to 1.4714148743138502e-05
Epoch: 14 cost time: 12.859940767288208
Epoch: 14, Steps: 20 | Train Loss: 0.7952551 Vali Loss: 0.4923158 Test Loss: 0.4314457
Validation loss decreased (0.518835 --> 0.492316).  Saving model ...
Updating learning rate to 1.634869134007758e-05
Epoch: 15 cost time: 12.546251058578491
Epoch: 15, Steps: 20 | Train Loss: 0.7673765 Vali Loss: 0.4776007 Test Loss: 0.4177628
Validation loss decreased (0.492316 --> 0.477601).  Saving model ...
Updating learning rate to 1.8081114725379524e-05
Epoch: 16 cost time: 12.347820281982422
Epoch: 16, Steps: 20 | Train Loss: 0.7433933 Vali Loss: 0.4697812 Test Loss: 0.4070275
Validation loss decreased (0.477601 --> 0.469781).  Saving model ...
Updating learning rate to 1.990666252478751e-05
Epoch: 17 cost time: 12.272810220718384
Epoch: 17, Steps: 20 | Train Loss: 0.7254536 Vali Loss: 0.4528102 Test Loss: 0.3984690
Validation loss decreased (0.469781 --> 0.452810).  Saving model ...
Updating learning rate to 2.1820322690651182e-05
Epoch: 18 cost time: 12.217337131500244
Epoch: 18, Steps: 20 | Train Loss: 0.7100334 Vali Loss: 0.4595456 Test Loss: 0.3913587
EarlyStopping counter: 1 out of 15
Updating learning rate to 2.381684126252048e-05
Epoch: 19 cost time: 12.234534740447998
Epoch: 19, Steps: 20 | Train Loss: 0.6970182 Vali Loss: 0.4533078 Test Loss: 0.3854540
EarlyStopping counter: 2 out of 15
Updating learning rate to 2.5890736791911714e-05
Epoch: 20 cost time: 12.269094944000244
Epoch: 20, Steps: 20 | Train Loss: 0.6837293 Vali Loss: 0.4307404 Test Loss: 0.3798731
Validation loss decreased (0.452810 --> 0.430740).  Saving model ...
Updating learning rate to 2.803631539164287e-05
Epoch: 21 cost time: 12.246934175491333
Epoch: 21, Steps: 20 | Train Loss: 0.6770157 Vali Loss: 0.4265102 Test Loss: 0.3750370
Validation loss decreased (0.430740 --> 0.426510).  Saving model ...
Updating learning rate to 3.024768636842028e-05
Epoch: 22 cost time: 12.184298992156982
Epoch: 22, Steps: 20 | Train Loss: 0.6647057 Vali Loss: 0.4394296 Test Loss: 0.3705309
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.2518778395756694e-05
Epoch: 23 cost time: 12.202039957046509
Epoch: 23, Steps: 20 | Train Loss: 0.6535742 Vali Loss: 0.4238716 Test Loss: 0.3664031
Validation loss decreased (0.426510 --> 0.423872).  Saving model ...
Updating learning rate to 3.484335618281891e-05
Epoch: 24 cost time: 12.248075485229492
Epoch: 24, Steps: 20 | Train Loss: 0.6482989 Vali Loss: 0.4267204 Test Loss: 0.3629774
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.721503759343966e-05
Epoch: 25 cost time: 12.204783201217651
Epoch: 25, Steps: 20 | Train Loss: 0.6401273 Vali Loss: 0.4181178 Test Loss: 0.3599265
Validation loss decreased (0.423872 --> 0.418118).  Saving model ...
Updating learning rate to 3.962731116829408e-05
Epoch: 26 cost time: 12.152227640151978
Epoch: 26, Steps: 20 | Train Loss: 0.6307127 Vali Loss: 0.4165552 Test Loss: 0.3570893
Validation loss decreased (0.418118 --> 0.416555).  Saving model ...
Updating learning rate to 4.207355400213329e-05
Epoch: 27 cost time: 12.134323835372925
Epoch: 27, Steps: 20 | Train Loss: 0.6255800 Vali Loss: 0.4107139 Test Loss: 0.3545769
Validation loss decreased (0.416555 --> 0.410714).  Saving model ...
Updating learning rate to 4.454704992699311e-05
Epoch: 28 cost time: 12.231350898742676
Epoch: 28, Steps: 20 | Train Loss: 0.6211740 Vali Loss: 0.3981063 Test Loss: 0.3521861
Validation loss decreased (0.410714 --> 0.398106).  Saving model ...
Updating learning rate to 4.7041007951455885e-05
Epoch: 29 cost time: 12.171307563781738
Epoch: 29, Steps: 20 | Train Loss: 0.6106017 Vali Loss: 0.4108369 Test Loss: 0.3502453
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.9548580905340365e-05
Epoch: 30 cost time: 12.228819131851196
Epoch: 30, Steps: 20 | Train Loss: 0.6094455 Vali Loss: 0.3970127 Test Loss: 0.3484929
Validation loss decreased (0.398106 --> 0.397013).  Saving model ...
Updating learning rate to 5.2062884238630596e-05
Epoch: 31 cost time: 12.267652750015259
Epoch: 31, Steps: 20 | Train Loss: 0.6045977 Vali Loss: 0.3992286 Test Loss: 0.3467142
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.4577014923031245e-05
Epoch: 32 cost time: 12.274733781814575
Epoch: 32, Steps: 20 | Train Loss: 0.5991490 Vali Loss: 0.3989307 Test Loss: 0.3453836
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.708407040425505e-05
Epoch: 33 cost time: 12.202308893203735
Epoch: 33, Steps: 20 | Train Loss: 0.5960992 Vali Loss: 0.3949918 Test Loss: 0.3437106
Validation loss decreased (0.397013 --> 0.394992).  Saving model ...
Updating learning rate to 5.957716755300899e-05
Epoch: 34 cost time: 12.242653608322144
Epoch: 34, Steps: 20 | Train Loss: 0.5931772 Vali Loss: 0.3876073 Test Loss: 0.3424452
Validation loss decreased (0.394992 --> 0.387607).  Saving model ...
Updating learning rate to 6.204946156264901e-05
Epoch: 35 cost time: 12.316767454147339
Epoch: 35, Steps: 20 | Train Loss: 0.5901561 Vali Loss: 0.3934286 Test Loss: 0.3413636
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.449416474161976e-05
Epoch: 36 cost time: 12.270825147628784
Epoch: 36, Steps: 20 | Train Loss: 0.5874115 Vali Loss: 0.3856452 Test Loss: 0.3402960
Validation loss decreased (0.387607 --> 0.385645).  Saving model ...
Updating learning rate to 6.690456514908466e-05
Epoch: 37 cost time: 12.250474691390991
Epoch: 37, Steps: 20 | Train Loss: 0.5845178 Vali Loss: 0.3861678 Test Loss: 0.3389736
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.927404502258226e-05
Epoch: 38 cost time: 12.288336753845215
Epoch: 38, Steps: 20 | Train Loss: 0.5808715 Vali Loss: 0.3858045 Test Loss: 0.3382688
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.159609894711528e-05
Epoch: 39 cost time: 12.3651704788208
Epoch: 39, Steps: 20 | Train Loss: 0.5778085 Vali Loss: 0.3777244 Test Loss: 0.3377185
Validation loss decreased (0.385645 --> 0.377724).  Saving model ...
Updating learning rate to 7.386435171578959e-05
Epoch: 40 cost time: 12.36076807975769
Epoch: 40, Steps: 20 | Train Loss: 0.5756192 Vali Loss: 0.3908938 Test Loss: 0.3365861
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.607257583296616e-05
Epoch: 41 cost time: 12.401236057281494
Epoch: 41, Steps: 20 | Train Loss: 0.5726761 Vali Loss: 0.3914326 Test Loss: 0.3357694
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.821470861187153e-05
Epoch: 42 cost time: 12.535934209823608
Epoch: 42, Steps: 20 | Train Loss: 0.5690721 Vali Loss: 0.3938706 Test Loss: 0.3354469
EarlyStopping counter: 3 out of 15
Updating learning rate to 8.028486881972461e-05
Epoch: 43 cost time: 12.563094139099121
Epoch: 43, Steps: 20 | Train Loss: 0.5678510 Vali Loss: 0.3809869 Test Loss: 0.3350546
EarlyStopping counter: 4 out of 15
Updating learning rate to 8.227737282468138e-05
Epoch: 44 cost time: 12.65761923789978
Epoch: 44, Steps: 20 | Train Loss: 0.5672752 Vali Loss: 0.3895808 Test Loss: 0.3346083
EarlyStopping counter: 5 out of 15
Updating learning rate to 8.418675020026516e-05
Epoch: 45 cost time: 12.718005895614624
Epoch: 45, Steps: 20 | Train Loss: 0.5649622 Vali Loss: 0.3778767 Test Loss: 0.3337193
EarlyStopping counter: 6 out of 15
Updating learning rate to 8.6007758744441e-05
Epoch: 46 cost time: 12.747249364852905
Epoch: 46, Steps: 20 | Train Loss: 0.5624547 Vali Loss: 0.3859518 Test Loss: 0.3333542
EarlyStopping counter: 7 out of 15
Updating learning rate to 8.773539887209924e-05
Epoch: 47 cost time: 12.725018978118896
Epoch: 47, Steps: 20 | Train Loss: 0.5609941 Vali Loss: 0.3746001 Test Loss: 0.3330225
Validation loss decreased (0.377724 --> 0.374600).  Saving model ...
Updating learning rate to 8.936492734143298e-05
Epoch: 48 cost time: 12.78293251991272
Epoch: 48, Steps: 20 | Train Loss: 0.5592706 Vali Loss: 0.3776794 Test Loss: 0.3331361
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.08918702765249e-05
Epoch: 49 cost time: 12.880937576293945
Epoch: 49, Steps: 20 | Train Loss: 0.5594123 Vali Loss: 0.3853583 Test Loss: 0.3326801
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.23120354503883e-05
Epoch: 50 cost time: 12.813315629959106
Epoch: 50, Steps: 20 | Train Loss: 0.5579741 Vali Loss: 0.3767660 Test Loss: 0.3326627
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.362152379474081e-05
Epoch: 51 cost time: 12.895070552825928
Epoch: 51, Steps: 20 | Train Loss: 0.5584056 Vali Loss: 0.3907454 Test Loss: 0.3324993
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.481674010490929e-05
Epoch: 52 cost time: 12.823952436447144
Epoch: 52, Steps: 20 | Train Loss: 0.5534733 Vali Loss: 0.3853080 Test Loss: 0.3322866
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.589440291047651e-05
Epoch: 53 cost time: 12.90621042251587
Epoch: 53, Steps: 20 | Train Loss: 0.5536246 Vali Loss: 0.3869447 Test Loss: 0.3325361
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.685155348456921e-05
Epoch: 54 cost time: 12.84236192703247
Epoch: 54, Steps: 20 | Train Loss: 0.5521832 Vali Loss: 0.3919237 Test Loss: 0.3319167
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.768556396705278e-05
Epoch: 55 cost time: 12.843827247619629
Epoch: 55, Steps: 20 | Train Loss: 0.5498512 Vali Loss: 0.3859668 Test Loss: 0.3316186
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.839414457933012e-05
Epoch: 56 cost time: 12.811687469482422
Epoch: 56, Steps: 20 | Train Loss: 0.5505075 Vali Loss: 0.3801121 Test Loss: 0.3317735
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.897534991093651e-05
Epoch: 57 cost time: 12.892688274383545
Epoch: 57, Steps: 20 | Train Loss: 0.5487579 Vali Loss: 0.3657727 Test Loss: 0.3324042
Validation loss decreased (0.374600 --> 0.365773).  Saving model ...
Updating learning rate to 9.942758426067059e-05
Epoch: 58 cost time: 12.871151208877563
Epoch: 58, Steps: 20 | Train Loss: 0.5485217 Vali Loss: 0.3884084 Test Loss: 0.3316568
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.974960601759743e-05
Epoch: 59 cost time: 12.913202285766602
Epoch: 59, Steps: 20 | Train Loss: 0.5488683 Vali Loss: 0.3796471 Test Loss: 0.3316014
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.994053106989553e-05
Epoch: 60 cost time: 12.95866584777832
Epoch: 60, Steps: 20 | Train Loss: 0.5455623 Vali Loss: 0.3811793 Test Loss: 0.3315434
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.999998929083705e-05
Epoch: 61 cost time: 12.872358083724976
Epoch: 61, Steps: 20 | Train Loss: 0.5455765 Vali Loss: 0.3740287 Test Loss: 0.3314513
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.999527733332e-05
Epoch: 62 cost time: 12.925860166549683
Epoch: 62, Steps: 20 | Train Loss: 0.5441630 Vali Loss: 0.3800882 Test Loss: 0.3310441
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.998199897667722e-05
Epoch: 63 cost time: 12.92529845237732
Epoch: 63, Steps: 20 | Train Loss: 0.5440292 Vali Loss: 0.3799260 Test Loss: 0.3314046
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.99601564960868e-05
Epoch: 64 cost time: 12.932865142822266
Epoch: 64, Steps: 20 | Train Loss: 0.5442331 Vali Loss: 0.3845212 Test Loss: 0.3311831
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.992975363414534e-05
Epoch: 65 cost time: 13.0182044506073
Epoch: 65, Steps: 20 | Train Loss: 0.5415469 Vali Loss: 0.3751890 Test Loss: 0.3314459
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.98907956002267e-05
Epoch: 66 cost time: 12.934086799621582
Epoch: 66, Steps: 20 | Train Loss: 0.5417376 Vali Loss: 0.3817263 Test Loss: 0.3319089
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.984328906958947e-05
Epoch: 67 cost time: 12.951850652694702
Epoch: 67, Steps: 20 | Train Loss: 0.5413463 Vali Loss: 0.3828288 Test Loss: 0.3318551
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.978724218223307e-05
Epoch: 68 cost time: 12.928719758987427
Epoch: 68, Steps: 20 | Train Loss: 0.5415543 Vali Loss: 0.3777905 Test Loss: 0.3312873
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.972266454150316e-05
Epoch: 69 cost time: 12.945690631866455
Epoch: 69, Steps: 20 | Train Loss: 0.5364740 Vali Loss: 0.3901311 Test Loss: 0.3313175
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.964956721244599e-05
Epoch: 70 cost time: 12.928878545761108
Epoch: 70, Steps: 20 | Train Loss: 0.5394356 Vali Loss: 0.3737007 Test Loss: 0.3310277
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.956796271991261e-05
Epoch: 71 cost time: 13.050376892089844
Epoch: 71, Steps: 20 | Train Loss: 0.5393941 Vali Loss: 0.3911753 Test Loss: 0.3306586
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.947786504641271e-05
Epoch: 72 cost time: 13.01041555404663
Epoch: 72, Steps: 20 | Train Loss: 0.5351140 Vali Loss: 0.3805292 Test Loss: 0.3312414
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : 240_3_PatchTST_custom_ftM_sl240_ll48_pl3_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5993
mse:0.3324042558670044, mae:0.3611771762371063, rse:0.7107667922973633
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='240_5', model='PatchTST', data='custom', root_path='../', data_path='BTCUSDT_1h_features.csv', features='M', target='ibs', freq='h', checkpoints='./checkpoints/', seq_len=240, label_len=48, pred_len=5, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=300, batch_size=1024, patience=15, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.2, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : 240_5_PatchTST_custom_ftM_sl240_ll48_pl5_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 20741
val 2995
test 5991
Epoch: 1 cost time: 12.989644050598145
Epoch: 1, Steps: 20 | Train Loss: 1.2956885 Vali Loss: 0.8077696 Test Loss: 0.7389861
Validation loss decreased (inf --> 0.807770).  Saving model ...
Updating learning rate to 4.065892081076648e-06
Epoch: 2 cost time: 12.890026569366455
Epoch: 2, Steps: 20 | Train Loss: 1.2580928 Vali Loss: 0.8169882 Test Loss: 0.7342733
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.263387417375412e-06
Epoch: 3 cost time: 12.857270002365112
Epoch: 3, Steps: 20 | Train Loss: 1.2221424 Vali Loss: 0.7990628 Test Loss: 0.7132127
Validation loss decreased (0.807770 --> 0.799063).  Saving model ...
Updating learning rate to 4.5919437847832866e-06
Epoch: 4 cost time: 12.906327247619629
Epoch: 4, Steps: 20 | Train Loss: 1.1880174 Vali Loss: 0.7748467 Test Loss: 0.6895954
Validation loss decreased (0.799063 --> 0.774847).  Saving model ...
Updating learning rate to 5.050659130683655e-06
Epoch: 5 cost time: 12.883478164672852
Epoch: 5, Steps: 20 | Train Loss: 1.1548231 Vali Loss: 0.7571404 Test Loss: 0.6655012
Validation loss decreased (0.774847 --> 0.757140).  Saving model ...
Updating learning rate to 5.638274050544684e-06
Epoch: 6 cost time: 12.927542686462402
Epoch: 6, Steps: 20 | Train Loss: 1.1195077 Vali Loss: 0.7157109 Test Loss: 0.6410963
Validation loss decreased (0.757140 --> 0.715711).  Saving model ...
Updating learning rate to 6.353175245618837e-06
Epoch: 7 cost time: 12.896024465560913
Epoch: 7, Steps: 20 | Train Loss: 1.0821415 Vali Loss: 0.7029694 Test Loss: 0.6166693
Validation loss decreased (0.715711 --> 0.702969).  Saving model ...
Updating learning rate to 7.193399952259961e-06
Epoch: 8 cost time: 12.924425601959229
Epoch: 8, Steps: 20 | Train Loss: 1.0440822 Vali Loss: 0.6685476 Test Loss: 0.5921057
Validation loss decreased (0.702969 --> 0.668548).  Saving model ...
Updating learning rate to 8.156641330697527e-06
Epoch: 9 cost time: 12.924522638320923
Epoch: 9, Steps: 20 | Train Loss: 1.0087266 Vali Loss: 0.6488479 Test Loss: 0.5679869
Validation loss decreased (0.668548 --> 0.648848).  Saving model ...
Updating learning rate to 9.240254798473037e-06
Epoch: 10 cost time: 12.935834169387817
Epoch: 10, Steps: 20 | Train Loss: 0.9721592 Vali Loss: 0.6201562 Test Loss: 0.5441834
Validation loss decreased (0.648848 --> 0.620156).  Saving model ...
Updating learning rate to 1.0441265291150027e-05
Epoch: 11 cost time: 13.004881381988525
Epoch: 11, Steps: 20 | Train Loss: 0.9361718 Vali Loss: 0.6021876 Test Loss: 0.5219595
Validation loss decreased (0.620156 --> 0.602188).  Saving model ...
Updating learning rate to 1.1756375430363637e-05
Epoch: 12 cost time: 12.987496614456177
Epoch: 12, Steps: 20 | Train Loss: 0.9040722 Vali Loss: 0.5894243 Test Loss: 0.5014308
Validation loss decreased (0.602188 --> 0.589424).  Saving model ...
Updating learning rate to 1.3181974576783947e-05
Epoch: 13 cost time: 12.964720487594604
Epoch: 13, Steps: 20 | Train Loss: 0.8757616 Vali Loss: 0.5616499 Test Loss: 0.4832687
Validation loss decreased (0.589424 --> 0.561650).  Saving model ...
Updating learning rate to 1.4714148743138502e-05
Epoch: 14 cost time: 12.960508108139038
Epoch: 14, Steps: 20 | Train Loss: 0.8440931 Vali Loss: 0.5454166 Test Loss: 0.4679205
Validation loss decreased (0.561650 --> 0.545417).  Saving model ...
Updating learning rate to 1.634869134007758e-05
Epoch: 15 cost time: 12.96341323852539
Epoch: 15, Steps: 20 | Train Loss: 0.8236311 Vali Loss: 0.5279634 Test Loss: 0.4549498
Validation loss decreased (0.545417 --> 0.527963).  Saving model ...
Updating learning rate to 1.8081114725379524e-05
Epoch: 16 cost time: 12.990226984024048
Epoch: 16, Steps: 20 | Train Loss: 0.8047285 Vali Loss: 0.5168161 Test Loss: 0.4449111
Validation loss decreased (0.527963 --> 0.516816).  Saving model ...
Updating learning rate to 1.990666252478751e-05
Epoch: 17 cost time: 12.967513799667358
Epoch: 17, Steps: 20 | Train Loss: 0.7876121 Vali Loss: 0.5031828 Test Loss: 0.4364387
Validation loss decreased (0.516816 --> 0.503183).  Saving model ...
Updating learning rate to 2.1820322690651182e-05
Epoch: 18 cost time: 12.942702770233154
Epoch: 18, Steps: 20 | Train Loss: 0.7685527 Vali Loss: 0.4993072 Test Loss: 0.4289290
Validation loss decreased (0.503183 --> 0.499307).  Saving model ...
Updating learning rate to 2.381684126252048e-05
Epoch: 19 cost time: 12.943960189819336
Epoch: 19, Steps: 20 | Train Loss: 0.7562722 Vali Loss: 0.4936110 Test Loss: 0.4224326
Validation loss decreased (0.499307 --> 0.493611).  Saving model ...
Updating learning rate to 2.5890736791911714e-05
Epoch: 20 cost time: 12.929346799850464
Epoch: 20, Steps: 20 | Train Loss: 0.7422696 Vali Loss: 0.4840427 Test Loss: 0.4163818
Validation loss decreased (0.493611 --> 0.484043).  Saving model ...
Updating learning rate to 2.803631539164287e-05
Epoch: 21 cost time: 12.933417081832886
Epoch: 21, Steps: 20 | Train Loss: 0.7321803 Vali Loss: 0.4768243 Test Loss: 0.4110928
Validation loss decreased (0.484043 --> 0.476824).  Saving model ...
Updating learning rate to 3.024768636842028e-05
Epoch: 22 cost time: 12.951725482940674
Epoch: 22, Steps: 20 | Train Loss: 0.7223076 Vali Loss: 0.4801049 Test Loss: 0.4061502
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.2518778395756694e-05
Epoch: 23 cost time: 12.922281980514526
Epoch: 23, Steps: 20 | Train Loss: 0.7055341 Vali Loss: 0.4560000 Test Loss: 0.4018309
Validation loss decreased (0.476824 --> 0.456000).  Saving model ...
Updating learning rate to 3.484335618281891e-05
Epoch: 24 cost time: 12.947852849960327
Epoch: 24, Steps: 20 | Train Loss: 0.6986274 Vali Loss: 0.4746279 Test Loss: 0.3980904
EarlyStopping counter: 1 out of 15
Updating learning rate to 3.721503759343966e-05
Epoch: 25 cost time: 12.907296657562256
Epoch: 25, Steps: 20 | Train Loss: 0.6891984 Vali Loss: 0.4632496 Test Loss: 0.3945574
EarlyStopping counter: 2 out of 15
Updating learning rate to 3.962731116829408e-05
Epoch: 26 cost time: 12.894006729125977
Epoch: 26, Steps: 20 | Train Loss: 0.6872319 Vali Loss: 0.4522729 Test Loss: 0.3916240
Validation loss decreased (0.456000 --> 0.452273).  Saving model ...
Updating learning rate to 4.207355400213329e-05
Epoch: 27 cost time: 12.935476779937744
Epoch: 27, Steps: 20 | Train Loss: 0.6797716 Vali Loss: 0.4417606 Test Loss: 0.3889630
Validation loss decreased (0.452273 --> 0.441761).  Saving model ...
Updating learning rate to 4.454704992699311e-05
Epoch: 28 cost time: 12.955941200256348
Epoch: 28, Steps: 20 | Train Loss: 0.6745277 Vali Loss: 0.4462473 Test Loss: 0.3864732
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.7041007951455885e-05
Epoch: 29 cost time: 12.898177862167358
Epoch: 29, Steps: 20 | Train Loss: 0.6697448 Vali Loss: 0.4527847 Test Loss: 0.3844483
EarlyStopping counter: 2 out of 15
Updating learning rate to 4.9548580905340365e-05
Epoch: 30 cost time: 12.882014274597168
Epoch: 30, Steps: 20 | Train Loss: 0.6632187 Vali Loss: 0.4271967 Test Loss: 0.3827521
Validation loss decreased (0.441761 --> 0.427197).  Saving model ...
Updating learning rate to 5.2062884238630596e-05
Epoch: 31 cost time: 12.98624300956726
Epoch: 31, Steps: 20 | Train Loss: 0.6625991 Vali Loss: 0.4483823 Test Loss: 0.3813028
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.4577014923031245e-05
Epoch: 32 cost time: 12.916192770004272
Epoch: 32, Steps: 20 | Train Loss: 0.6544534 Vali Loss: 0.4406796 Test Loss: 0.3799801
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.708407040425505e-05
Epoch: 33 cost time: 12.884982109069824
Epoch: 33, Steps: 20 | Train Loss: 0.6551711 Vali Loss: 0.4367587 Test Loss: 0.3788803
EarlyStopping counter: 3 out of 15
Updating learning rate to 5.957716755300899e-05
Epoch: 34 cost time: 12.93344521522522
Epoch: 34, Steps: 20 | Train Loss: 0.6496027 Vali Loss: 0.4372332 Test Loss: 0.3784229
EarlyStopping counter: 4 out of 15
Updating learning rate to 6.204946156264901e-05
Epoch: 35 cost time: 12.909935235977173
Epoch: 35, Steps: 20 | Train Loss: 0.6442387 Vali Loss: 0.4293652 Test Loss: 0.3770590
EarlyStopping counter: 5 out of 15
Updating learning rate to 6.449416474161976e-05
Epoch: 36 cost time: 12.931029796600342
Epoch: 36, Steps: 20 | Train Loss: 0.6453412 Vali Loss: 0.4389772 Test Loss: 0.3757678
EarlyStopping counter: 6 out of 15
Updating learning rate to 6.690456514908466e-05
Epoch: 37 cost time: 12.944851160049438
Epoch: 37, Steps: 20 | Train Loss: 0.6410750 Vali Loss: 0.4354481 Test Loss: 0.3752271
EarlyStopping counter: 7 out of 15
Updating learning rate to 6.927404502258226e-05
Epoch: 38 cost time: 12.855046033859253
Epoch: 38, Steps: 20 | Train Loss: 0.6388426 Vali Loss: 0.4271951 Test Loss: 0.3748867
Validation loss decreased (0.427197 --> 0.427195).  Saving model ...
Updating learning rate to 7.159609894711528e-05
Epoch: 39 cost time: 12.886075735092163
Epoch: 39, Steps: 20 | Train Loss: 0.6367023 Vali Loss: 0.4225276 Test Loss: 0.3736505
Validation loss decreased (0.427195 --> 0.422528).  Saving model ...
Updating learning rate to 7.386435171578959e-05
Epoch: 40 cost time: 12.918822050094604
Epoch: 40, Steps: 20 | Train Loss: 0.6351011 Vali Loss: 0.4426199 Test Loss: 0.3730062
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.607257583296616e-05
Epoch: 41 cost time: 12.85555362701416
Epoch: 41, Steps: 20 | Train Loss: 0.6264611 Vali Loss: 0.4395954 Test Loss: 0.3732821
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.821470861187153e-05
Epoch: 42 cost time: 12.88701319694519
Epoch: 42, Steps: 20 | Train Loss: 0.6329262 Vali Loss: 0.4360951 Test Loss: 0.3722260
EarlyStopping counter: 3 out of 15
Updating learning rate to 8.028486881972461e-05
Epoch: 43 cost time: 12.97942304611206
Epoch: 43, Steps: 20 | Train Loss: 0.6287518 Vali Loss: 0.4292883 Test Loss: 0.3718932
EarlyStopping counter: 4 out of 15
Updating learning rate to 8.227737282468138e-05
Epoch: 44 cost time: 12.868948221206665
Epoch: 44, Steps: 20 | Train Loss: 0.6265967 Vali Loss: 0.4312318 Test Loss: 0.3714935
EarlyStopping counter: 5 out of 15
Updating learning rate to 8.418675020026516e-05
Epoch: 45 cost time: 12.994523763656616
Epoch: 45, Steps: 20 | Train Loss: 0.6237100 Vali Loss: 0.4324690 Test Loss: 0.3712046
EarlyStopping counter: 6 out of 15
Updating learning rate to 8.6007758744441e-05
Epoch: 46 cost time: 12.928110599517822
Epoch: 46, Steps: 20 | Train Loss: 0.6242167 Vali Loss: 0.4337232 Test Loss: 0.3708753
EarlyStopping counter: 7 out of 15
Updating learning rate to 8.773539887209924e-05
Epoch: 47 cost time: 12.84005856513977
Epoch: 47, Steps: 20 | Train Loss: 0.6221515 Vali Loss: 0.4225042 Test Loss: 0.3712051
Validation loss decreased (0.422528 --> 0.422504).  Saving model ...
Updating learning rate to 8.936492734143298e-05
Epoch: 48 cost time: 12.953035831451416
Epoch: 48, Steps: 20 | Train Loss: 0.6215039 Vali Loss: 0.4257756 Test Loss: 0.3701614
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.08918702765249e-05
Epoch: 49 cost time: 13.009773969650269
Epoch: 49, Steps: 20 | Train Loss: 0.6191689 Vali Loss: 0.4329705 Test Loss: 0.3706330
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.23120354503883e-05
Epoch: 50 cost time: 13.002193689346313
Epoch: 50, Steps: 20 | Train Loss: 0.6186897 Vali Loss: 0.4276723 Test Loss: 0.3704471
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.362152379474081e-05
Epoch: 51 cost time: 12.983464241027832
Epoch: 51, Steps: 20 | Train Loss: 0.6162940 Vali Loss: 0.4265057 Test Loss: 0.3697488
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.481674010490929e-05
Epoch: 52 cost time: 12.965866565704346
Epoch: 52, Steps: 20 | Train Loss: 0.6158460 Vali Loss: 0.4232826 Test Loss: 0.3697501
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.589440291047651e-05
Epoch: 53 cost time: 12.946593999862671
Epoch: 53, Steps: 20 | Train Loss: 0.6153389 Vali Loss: 0.4260911 Test Loss: 0.3699765
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.685155348456921e-05
Epoch: 54 cost time: 12.971837997436523
Epoch: 54, Steps: 20 | Train Loss: 0.6141374 Vali Loss: 0.4211227 Test Loss: 0.3700261
Validation loss decreased (0.422504 --> 0.421123).  Saving model ...
Updating learning rate to 9.768556396705278e-05
Epoch: 55 cost time: 12.934688091278076
Epoch: 55, Steps: 20 | Train Loss: 0.6118760 Vali Loss: 0.4246917 Test Loss: 0.3696447
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.839414457933012e-05
Epoch: 56 cost time: 13.00184154510498
Epoch: 56, Steps: 20 | Train Loss: 0.6125749 Vali Loss: 0.4272870 Test Loss: 0.3693495
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.897534991093651e-05
Epoch: 57 cost time: 12.998645544052124
Epoch: 57, Steps: 20 | Train Loss: 0.6116998 Vali Loss: 0.4245051 Test Loss: 0.3693259
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.942758426067059e-05
Epoch: 58 cost time: 12.935271739959717
Epoch: 58, Steps: 20 | Train Loss: 0.6115612 Vali Loss: 0.4228225 Test Loss: 0.3696814
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.974960601759743e-05
Epoch: 59 cost time: 12.942449808120728
Epoch: 59, Steps: 20 | Train Loss: 0.6067625 Vali Loss: 0.4283113 Test Loss: 0.3689757
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.994053106989553e-05
Epoch: 60 cost time: 12.975411415100098
Epoch: 60, Steps: 20 | Train Loss: 0.6070129 Vali Loss: 0.4292961 Test Loss: 0.3687470
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.999998929083705e-05
Epoch: 61 cost time: 12.999131202697754
Epoch: 61, Steps: 20 | Train Loss: 0.6040817 Vali Loss: 0.4212810 Test Loss: 0.3691414
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.999527733332e-05
Epoch: 62 cost time: 13.02763557434082
Epoch: 62, Steps: 20 | Train Loss: 0.6064315 Vali Loss: 0.4253686 Test Loss: 0.3689808
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.998199897667722e-05
Epoch: 63 cost time: 13.041953802108765
Epoch: 63, Steps: 20 | Train Loss: 0.6051724 Vali Loss: 0.4260249 Test Loss: 0.3686496
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.99601564960868e-05
Epoch: 64 cost time: 12.957229614257812
Epoch: 64, Steps: 20 | Train Loss: 0.6042327 Vali Loss: 0.4268968 Test Loss: 0.3691714
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.992975363414534e-05
Epoch: 65 cost time: 12.955104112625122
Epoch: 65, Steps: 20 | Train Loss: 0.6016359 Vali Loss: 0.4318911 Test Loss: 0.3686300
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.98907956002267e-05
Epoch: 66 cost time: 12.95309567451477
Epoch: 66, Steps: 20 | Train Loss: 0.6040548 Vali Loss: 0.4350838 Test Loss: 0.3689758
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.984328906958947e-05
Epoch: 67 cost time: 12.974094867706299
Epoch: 67, Steps: 20 | Train Loss: 0.6034105 Vali Loss: 0.4275119 Test Loss: 0.3686487
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.978724218223307e-05
Epoch: 68 cost time: 12.96141242980957
Epoch: 68, Steps: 20 | Train Loss: 0.6018761 Vali Loss: 0.4289938 Test Loss: 0.3684831
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.972266454150316e-05
Epoch: 69 cost time: 13.001638412475586
Epoch: 69, Steps: 20 | Train Loss: 0.6003282 Vali Loss: 0.4160594 Test Loss: 0.3692649
Validation loss decreased (0.421123 --> 0.416059).  Saving model ...
Updating learning rate to 9.964956721244599e-05
Epoch: 70 cost time: 13.003553867340088
Epoch: 70, Steps: 20 | Train Loss: 0.5997513 Vali Loss: 0.4353115 Test Loss: 0.3683933
EarlyStopping counter: 1 out of 15
Updating learning rate to 9.956796271991261e-05
Epoch: 71 cost time: 12.962623596191406
Epoch: 71, Steps: 20 | Train Loss: 0.6008730 Vali Loss: 0.4218372 Test Loss: 0.3683921
EarlyStopping counter: 2 out of 15
Updating learning rate to 9.947786504641271e-05
Epoch: 72 cost time: 12.910445213317871
Epoch: 72, Steps: 20 | Train Loss: 0.5989400 Vali Loss: 0.4297322 Test Loss: 0.3681439
EarlyStopping counter: 3 out of 15
Updating learning rate to 9.937928962971883e-05
Epoch: 73 cost time: 13.004794359207153
Epoch: 73, Steps: 20 | Train Loss: 0.5993139 Vali Loss: 0.4344800 Test Loss: 0.3695533
EarlyStopping counter: 4 out of 15
Updating learning rate to 9.927225336022116e-05
Epoch: 74 cost time: 12.999418497085571
Epoch: 74, Steps: 20 | Train Loss: 0.5986938 Vali Loss: 0.4362116 Test Loss: 0.3682876
EarlyStopping counter: 5 out of 15
Updating learning rate to 9.915677457803341e-05
Epoch: 75 cost time: 12.845511436462402
Epoch: 75, Steps: 20 | Train Loss: 0.5937299 Vali Loss: 0.4287344 Test Loss: 0.3678912
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.903287306985046e-05
Epoch: 76 cost time: 12.500787496566772
Epoch: 76, Steps: 20 | Train Loss: 0.5965870 Vali Loss: 0.4305709 Test Loss: 0.3682282
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.890057006555789e-05
Epoch: 77 cost time: 12.306610345840454
Epoch: 77, Steps: 20 | Train Loss: 0.5960522 Vali Loss: 0.4350563 Test Loss: 0.3679017
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.875988823459438e-05
Epoch: 78 cost time: 12.626217126846313
Epoch: 78, Steps: 20 | Train Loss: 0.5974666 Vali Loss: 0.4267222 Test Loss: 0.3679846
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.861085168206742e-05
Epoch: 79 cost time: 12.484960556030273
Epoch: 79, Steps: 20 | Train Loss: 0.5951593 Vali Loss: 0.4265108 Test Loss: 0.3682334
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.845348594462308e-05
Epoch: 80 cost time: 12.43037462234497
Epoch: 80, Steps: 20 | Train Loss: 0.5898002 Vali Loss: 0.4190364 Test Loss: 0.3682921
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.828781798607029e-05
Epoch: 81 cost time: 12.546802520751953
Epoch: 81, Steps: 20 | Train Loss: 0.5920539 Vali Loss: 0.4277080 Test Loss: 0.3677246
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.811387619276097e-05
Epoch: 82 cost time: 12.287433624267578
Epoch: 82, Steps: 20 | Train Loss: 0.5935141 Vali Loss: 0.4289349 Test Loss: 0.3681063
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.793169036872587e-05
Epoch: 83 cost time: 12.129467487335205
Epoch: 83, Steps: 20 | Train Loss: 0.5930811 Vali Loss: 0.4205658 Test Loss: 0.3677694
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.774129173056809e-05
Epoch: 84 cost time: 12.205581903457642
Epoch: 84, Steps: 20 | Train Loss: 0.5917135 Vali Loss: 0.4335391 Test Loss: 0.3682628
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : 240_5_PatchTST_custom_ftM_sl240_ll48_pl5_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5991
mse:0.36926499009132385, mae:0.3903149664402008, rse:0.7491545081138611
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='240_10', model='PatchTST', data='custom', root_path='../', data_path='BTCUSDT_1h_features.csv', features='M', target='ibs', freq='h', checkpoints='./checkpoints/', seq_len=240, label_len=48, pred_len=10, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=300, batch_size=1024, patience=15, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.2, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : 240_10_PatchTST_custom_ftM_sl240_ll48_pl10_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 20736
val 2990
test 5986
Epoch: 1 cost time: 12.308659076690674
Epoch: 1, Steps: 20 | Train Loss: 1.2909613 Vali Loss: 0.8135979 Test Loss: 0.7511533
Validation loss decreased (inf --> 0.813598).  Saving model ...
Updating learning rate to 4.065892081076648e-06
Epoch: 2 cost time: 12.267088174819946
Epoch: 2, Steps: 20 | Train Loss: 1.2680779 Vali Loss: 0.8298056 Test Loss: 0.7497610
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.263387417375412e-06
Epoch: 3 cost time: 12.259998083114624
Epoch: 3, Steps: 20 | Train Loss: 1.2403168 Vali Loss: 0.8039535 Test Loss: 0.7330860
Validation loss decreased (0.813598 --> 0.803954).  Saving model ...
Updating learning rate to 4.5919437847832866e-06
Epoch: 4 cost time: 12.335864782333374
Epoch: 4, Steps: 20 | Train Loss: 1.2133184 Vali Loss: 0.7958825 Test Loss: 0.7141577
Validation loss decreased (0.803954 --> 0.795882).  Saving model ...
Updating learning rate to 5.050659130683655e-06
Epoch: 5 cost time: 12.38396143913269
Epoch: 5, Steps: 20 | Train Loss: 1.1801457 Vali Loss: 0.7573612 Test Loss: 0.6947626
Validation loss decreased (0.795882 --> 0.757361).  Saving model ...
Updating learning rate to 5.638274050544684e-06
Epoch: 6 cost time: 12.346843481063843
Epoch: 6, Steps: 20 | Train Loss: 1.1545699 Vali Loss: 0.7485183 Test Loss: 0.6750197
Validation loss decreased (0.757361 --> 0.748518).  Saving model ...
Updating learning rate to 6.353175245618837e-06
Epoch: 7 cost time: 12.420266389846802
Epoch: 7, Steps: 20 | Train Loss: 1.1228145 Vali Loss: 0.7193404 Test Loss: 0.6550648
Validation loss decreased (0.748518 --> 0.719340).  Saving model ...
Updating learning rate to 7.193399952259961e-06
Epoch: 8 cost time: 12.479598045349121
Epoch: 8, Steps: 20 | Train Loss: 1.0967260 Vali Loss: 0.6980257 Test Loss: 0.6346549
Validation loss decreased (0.719340 --> 0.698026).  Saving model ...
Updating learning rate to 8.156641330697527e-06
Epoch: 9 cost time: 12.635527849197388
Epoch: 9, Steps: 20 | Train Loss: 1.0623088 Vali Loss: 0.6848639 Test Loss: 0.6143550
Validation loss decreased (0.698026 --> 0.684864).  Saving model ...
Updating learning rate to 9.240254798473037e-06
Epoch: 10 cost time: 12.576652526855469
Epoch: 10, Steps: 20 | Train Loss: 1.0360757 Vali Loss: 0.6610949 Test Loss: 0.5941399
Validation loss decreased (0.684864 --> 0.661095).  Saving model ...
Updating learning rate to 1.0441265291150027e-05
Epoch: 11 cost time: 12.602280616760254
Epoch: 11, Steps: 20 | Train Loss: 1.0048287 Vali Loss: 0.6357590 Test Loss: 0.5746359
Validation loss decreased (0.661095 --> 0.635759).  Saving model ...
Updating learning rate to 1.1756375430363637e-05
Epoch: 12 cost time: 12.691894292831421
Epoch: 12, Steps: 20 | Train Loss: 0.9787799 Vali Loss: 0.6392111 Test Loss: 0.5565215
EarlyStopping counter: 1 out of 15
Updating learning rate to 1.3181974576783947e-05
Epoch: 13 cost time: 12.756457805633545
Epoch: 13, Steps: 20 | Train Loss: 0.9520076 Vali Loss: 0.6214996 Test Loss: 0.5403856
Validation loss decreased (0.635759 --> 0.621500).  Saving model ...
Updating learning rate to 1.4714148743138502e-05
Epoch: 14 cost time: 12.805364608764648
Epoch: 14, Steps: 20 | Train Loss: 0.9278976 Vali Loss: 0.6112698 Test Loss: 0.5263377
Validation loss decreased (0.621500 --> 0.611270).  Saving model ...
Updating learning rate to 1.634869134007758e-05
Epoch: 15 cost time: 12.65656042098999
Epoch: 15, Steps: 20 | Train Loss: 0.9055234 Vali Loss: 0.5955867 Test Loss: 0.5143656
Validation loss decreased (0.611270 --> 0.595587).  Saving model ...
Updating learning rate to 1.8081114725379524e-05
Epoch: 16 cost time: 12.428685665130615
Epoch: 16, Steps: 20 | Train Loss: 0.8890788 Vali Loss: 0.5776235 Test Loss: 0.5046647
Validation loss decreased (0.595587 --> 0.577623).  Saving model ...
Updating learning rate to 1.990666252478751e-05
Epoch: 17 cost time: 12.292881965637207
Epoch: 17, Steps: 20 | Train Loss: 0.8704887 Vali Loss: 0.5700705 Test Loss: 0.4963888
Validation loss decreased (0.577623 --> 0.570071).  Saving model ...
Updating learning rate to 2.1820322690651182e-05
Epoch: 18 cost time: 12.232460498809814
Epoch: 18, Steps: 20 | Train Loss: 0.8513920 Vali Loss: 0.5677537 Test Loss: 0.4893462
Validation loss decreased (0.570071 --> 0.567754).  Saving model ...
Updating learning rate to 2.381684126252048e-05
Epoch: 19 cost time: 12.167214632034302
Epoch: 19, Steps: 20 | Train Loss: 0.8407482 Vali Loss: 0.5484347 Test Loss: 0.4827797
Validation loss decreased (0.567754 --> 0.548435).  Saving model ...
Updating learning rate to 2.5890736791911714e-05
Epoch: 20 cost time: 12.157032489776611
Epoch: 20, Steps: 20 | Train Loss: 0.8265047 Vali Loss: 0.5413682 Test Loss: 0.4772606
Validation loss decreased (0.548435 --> 0.541368).  Saving model ...
Updating learning rate to 2.803631539164287e-05
Epoch: 21 cost time: 12.261250257492065
Epoch: 21, Steps: 20 | Train Loss: 0.8129467 Vali Loss: 0.5386608 Test Loss: 0.4718720
Validation loss decreased (0.541368 --> 0.538661).  Saving model ...
Updating learning rate to 3.024768636842028e-05
Epoch: 22 cost time: 12.169629573822021
Epoch: 22, Steps: 20 | Train Loss: 0.8050219 Vali Loss: 0.5370703 Test Loss: 0.4672632
Validation loss decreased (0.538661 --> 0.537070).  Saving model ...
Updating learning rate to 3.2518778395756694e-05
Epoch: 23 cost time: 12.239246368408203
Epoch: 23, Steps: 20 | Train Loss: 0.7973112 Vali Loss: 0.5334743 Test Loss: 0.4631492
Validation loss decreased (0.537070 --> 0.533474).  Saving model ...
Updating learning rate to 3.484335618281891e-05
Epoch: 24 cost time: 12.280904531478882
Epoch: 24, Steps: 20 | Train Loss: 0.7861189 Vali Loss: 0.5285776 Test Loss: 0.4589658
Validation loss decreased (0.533474 --> 0.528578).  Saving model ...
Updating learning rate to 3.721503759343966e-05
Epoch: 25 cost time: 12.22645354270935
Epoch: 25, Steps: 20 | Train Loss: 0.7815260 Vali Loss: 0.5220922 Test Loss: 0.4560627
Validation loss decreased (0.528578 --> 0.522092).  Saving model ...
Updating learning rate to 3.962731116829408e-05
Epoch: 26 cost time: 12.215298414230347
Epoch: 26, Steps: 20 | Train Loss: 0.7759462 Vali Loss: 0.5272200 Test Loss: 0.4528568
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.207355400213329e-05
Epoch: 27 cost time: 12.235240459442139
Epoch: 27, Steps: 20 | Train Loss: 0.7687067 Vali Loss: 0.5197915 Test Loss: 0.4503189
Validation loss decreased (0.522092 --> 0.519791).  Saving model ...
Updating learning rate to 4.454704992699311e-05
Epoch: 28 cost time: 12.263821840286255
Epoch: 28, Steps: 20 | Train Loss: 0.7642158 Vali Loss: 0.5182364 Test Loss: 0.4486326
Validation loss decreased (0.519791 --> 0.518236).  Saving model ...
Updating learning rate to 4.7041007951455885e-05
Epoch: 29 cost time: 12.337559700012207
Epoch: 29, Steps: 20 | Train Loss: 0.7560467 Vali Loss: 0.5211878 Test Loss: 0.4462715
EarlyStopping counter: 1 out of 15
Updating learning rate to 4.9548580905340365e-05
Epoch: 30 cost time: 12.344970464706421
Epoch: 30, Steps: 20 | Train Loss: 0.7560072 Vali Loss: 0.5179568 Test Loss: 0.4446612
Validation loss decreased (0.518236 --> 0.517957).  Saving model ...
Updating learning rate to 5.2062884238630596e-05
Epoch: 31 cost time: 12.40334439277649
Epoch: 31, Steps: 20 | Train Loss: 0.7515046 Vali Loss: 0.5073100 Test Loss: 0.4433151
Validation loss decreased (0.517957 --> 0.507310).  Saving model ...
Updating learning rate to 5.4577014923031245e-05
Epoch: 32 cost time: 12.465866804122925
Epoch: 32, Steps: 20 | Train Loss: 0.7495640 Vali Loss: 0.5240521 Test Loss: 0.4423262
EarlyStopping counter: 1 out of 15
Updating learning rate to 5.708407040425505e-05
Epoch: 33 cost time: 12.555289268493652
Epoch: 33, Steps: 20 | Train Loss: 0.7479715 Vali Loss: 0.5197486 Test Loss: 0.4417030
EarlyStopping counter: 2 out of 15
Updating learning rate to 5.957716755300899e-05
Epoch: 34 cost time: 12.556058883666992
Epoch: 34, Steps: 20 | Train Loss: 0.7444479 Vali Loss: 0.5073092 Test Loss: 0.4412868
Validation loss decreased (0.507310 --> 0.507309).  Saving model ...
Updating learning rate to 6.204946156264901e-05
Epoch: 35 cost time: 12.597079277038574
Epoch: 35, Steps: 20 | Train Loss: 0.7410694 Vali Loss: 0.5231467 Test Loss: 0.4403931
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.449416474161976e-05
Epoch: 36 cost time: 12.667982578277588
Epoch: 36, Steps: 20 | Train Loss: 0.7386313 Vali Loss: 0.5061453 Test Loss: 0.4385664
Validation loss decreased (0.507309 --> 0.506145).  Saving model ...
Updating learning rate to 6.690456514908466e-05
Epoch: 37 cost time: 12.787537813186646
Epoch: 37, Steps: 20 | Train Loss: 0.7367035 Vali Loss: 0.5144313 Test Loss: 0.4384133
EarlyStopping counter: 1 out of 15
Updating learning rate to 6.927404502258226e-05
Epoch: 38 cost time: 12.869737386703491
Epoch: 38, Steps: 20 | Train Loss: 0.7307927 Vali Loss: 0.5046467 Test Loss: 0.4379633
Validation loss decreased (0.506145 --> 0.504647).  Saving model ...
Updating learning rate to 7.159609894711528e-05
Epoch: 39 cost time: 12.785606622695923
Epoch: 39, Steps: 20 | Train Loss: 0.7329447 Vali Loss: 0.5120358 Test Loss: 0.4370260
EarlyStopping counter: 1 out of 15
Updating learning rate to 7.386435171578959e-05
Epoch: 40 cost time: 12.817564249038696
Epoch: 40, Steps: 20 | Train Loss: 0.7297382 Vali Loss: 0.5111712 Test Loss: 0.4361362
EarlyStopping counter: 2 out of 15
Updating learning rate to 7.607257583296616e-05
Epoch: 41 cost time: 12.79130506515503
Epoch: 41, Steps: 20 | Train Loss: 0.7291828 Vali Loss: 0.5032420 Test Loss: 0.4356457
Validation loss decreased (0.504647 --> 0.503242).  Saving model ...
Updating learning rate to 7.821470861187153e-05
Epoch: 42 cost time: 12.790716409683228
Epoch: 42, Steps: 20 | Train Loss: 0.7257698 Vali Loss: 0.4972063 Test Loss: 0.4356627
Validation loss decreased (0.503242 --> 0.497206).  Saving model ...
Updating learning rate to 8.028486881972461e-05
Epoch: 43 cost time: 12.860914707183838
Epoch: 43, Steps: 20 | Train Loss: 0.7245310 Vali Loss: 0.5028806 Test Loss: 0.4348483
EarlyStopping counter: 1 out of 15
Updating learning rate to 8.227737282468138e-05
Epoch: 44 cost time: 12.819442987442017
Epoch: 44, Steps: 20 | Train Loss: 0.7229360 Vali Loss: 0.5070242 Test Loss: 0.4339784
EarlyStopping counter: 2 out of 15
Updating learning rate to 8.418675020026516e-05
Epoch: 45 cost time: 12.836081504821777
Epoch: 45, Steps: 20 | Train Loss: 0.7195937 Vali Loss: 0.5048271 Test Loss: 0.4347678
EarlyStopping counter: 3 out of 15
Updating learning rate to 8.6007758744441e-05
Epoch: 46 cost time: 12.909419536590576
Epoch: 46, Steps: 20 | Train Loss: 0.7214435 Vali Loss: 0.5063007 Test Loss: 0.4339627
EarlyStopping counter: 4 out of 15
Updating learning rate to 8.773539887209924e-05
Epoch: 47 cost time: 12.852755069732666
Epoch: 47, Steps: 20 | Train Loss: 0.7197940 Vali Loss: 0.5075133 Test Loss: 0.4330239
EarlyStopping counter: 5 out of 15
Updating learning rate to 8.936492734143298e-05
Epoch: 48 cost time: 12.871058940887451
Epoch: 48, Steps: 20 | Train Loss: 0.7192531 Vali Loss: 0.5014719 Test Loss: 0.4354118
EarlyStopping counter: 6 out of 15
Updating learning rate to 9.08918702765249e-05
Epoch: 49 cost time: 12.923069477081299
Epoch: 49, Steps: 20 | Train Loss: 0.7156439 Vali Loss: 0.5013275 Test Loss: 0.4324507
EarlyStopping counter: 7 out of 15
Updating learning rate to 9.23120354503883e-05
Epoch: 50 cost time: 12.996548414230347
Epoch: 50, Steps: 20 | Train Loss: 0.7150913 Vali Loss: 0.4980453 Test Loss: 0.4329733
EarlyStopping counter: 8 out of 15
Updating learning rate to 9.362152379474081e-05
Epoch: 51 cost time: 12.96685266494751
Epoch: 51, Steps: 20 | Train Loss: 0.7149370 Vali Loss: 0.5053338 Test Loss: 0.4324741
EarlyStopping counter: 9 out of 15
Updating learning rate to 9.481674010490929e-05
Epoch: 52 cost time: 12.897424936294556
Epoch: 52, Steps: 20 | Train Loss: 0.7116487 Vali Loss: 0.5036215 Test Loss: 0.4320257
EarlyStopping counter: 10 out of 15
Updating learning rate to 9.589440291047651e-05
Epoch: 53 cost time: 12.946254253387451
Epoch: 53, Steps: 20 | Train Loss: 0.7111922 Vali Loss: 0.5053519 Test Loss: 0.4322525
EarlyStopping counter: 11 out of 15
Updating learning rate to 9.685155348456921e-05
Epoch: 54 cost time: 12.991254806518555
Epoch: 54, Steps: 20 | Train Loss: 0.7121300 Vali Loss: 0.5017522 Test Loss: 0.4318904
EarlyStopping counter: 12 out of 15
Updating learning rate to 9.768556396705278e-05
Epoch: 55 cost time: 12.941615104675293
Epoch: 55, Steps: 20 | Train Loss: 0.7081166 Vali Loss: 0.5125682 Test Loss: 0.4322572
EarlyStopping counter: 13 out of 15
Updating learning rate to 9.839414457933012e-05
Epoch: 56 cost time: 13.014088869094849
Epoch: 56, Steps: 20 | Train Loss: 0.7075167 Vali Loss: 0.5029283 Test Loss: 0.4316503
EarlyStopping counter: 14 out of 15
Updating learning rate to 9.897534991093651e-05
Epoch: 57 cost time: 12.95665717124939
Epoch: 57, Steps: 20 | Train Loss: 0.7059889 Vali Loss: 0.5077662 Test Loss: 0.4325776
EarlyStopping counter: 15 out of 15
Early stopping
>>>>>>>testing : 240_10_PatchTST_custom_ftM_sl240_ll48_pl10_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5986
mse:0.43566271662712097, mae:0.4423759877681732, rse:0.8137049674987793
